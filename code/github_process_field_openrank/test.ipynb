{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "df = pd.read_excel(\"repo_list_github_field.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to field_process.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def replace_tags(tag):\n",
    "    target_tags = [\"Cloud Native\", \"Artificial Intelligence\", \"Database\", \"BigData\"]\n",
    "    for target_tag in target_tags:\n",
    "        if target_tag.lower() in tag.lower():  # 将比较操作转换为小写，避免大小写敏感问题\n",
    "            return target_tag\n",
    "    return tag\n",
    "\n",
    "\n",
    "# 假设文件与脚本在同一目录下，直接使用文件名\n",
    "file_path = 'repo_list_github_field.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "def process_tags(row):\n",
    "    all_tags = row[\"field\"].split(', ')\n",
    "    processed_tags = [replace_tags(tag.strip()) for tag in all_tags]\n",
    "    unique_processed_tags = list(set(processed_tags))  # 去重操作\n",
    "    return unique_processed_tags\n",
    "\n",
    "\n",
    "df[\"field\"] = df.apply(process_tags, axis=1)\n",
    "\n",
    "\n",
    "# 整理数据，每个条数据对应一个仓库和一个标签\n",
    "tags_with_repositories = []\n",
    "for idx, row in df.iterrows():\n",
    "    repo_name = row[\"repo_name\"]\n",
    "    for tag in row[\"field\"]:\n",
    "        tags_with_repositories.append({\"Repository\": repo_name, \"Tag\": tag})\n",
    "\n",
    "\n",
    "tags_repositories_df = pd.DataFrame(tags_with_repositories)\n",
    "\n",
    "\n",
    "output_file_path = 'field_process.xlsx'\n",
    "tags_repositories_df.to_excel(output_file_path, index=False)\n",
    "\n",
    "\n",
    "print(f\"Output saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Tag  Count\n",
      "0                       Cloud Native   1737\n",
      "1                           Database   1240\n",
      "2            Artificial Intelligence   1136\n",
      "3                           Big Data    232\n",
      "4                           Frontend    111\n",
      "5                   Operating System     86\n",
      "6                        Block Chain     40\n",
      "7                 Internet of Things     35\n",
      "8  Registries & Application Delivery      1\n",
      "                                 Tag  \\\n",
      "0            Artificial Intelligence   \n",
      "1                           Big Data   \n",
      "2                        Block Chain   \n",
      "3                       Cloud Native   \n",
      "4                           Database   \n",
      "5                           Frontend   \n",
      "6                 Internet of Things   \n",
      "7                   Operating System   \n",
      "8  Registries & Application Delivery   \n",
      "\n",
      "                                          Repository  \n",
      "0  [pytorch/pytorch, vllm-project/vllm, vllm-proj...  \n",
      "1  [elastic/kibana, elastic/kibana, grafana/grafa...  \n",
      "2  [smartcontractkit/chainlink, bitcoin/bitcoin, ...  \n",
      "3  [llvm/llvm-project, llvm/llvm-project, llvm/ll...  \n",
      "4  [ClickHouse/ClickHouse, ClickHouse/ClickHouse,...  \n",
      "5  [flutter/flutter, vercel/next.js, facebook/rea...  \n",
      "6  [zephyrproject-rtos/zephyr, openwrt/openwrt, e...  \n",
      "7  [reactos/reactos, torvalds/linux, SerenityOS/s...  \n",
      "8                              [opencontainers/runc]  \n",
      "Output saved to data_field/tags_repositories_statistics.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def replace_tags(tag):\n",
    "    target_tags = [\"Cloud Native\", \"Artificial Intelligence\", \"Database\", \"Big Data\"]\n",
    "    for target_tag in target_tags:\n",
    "        if target_tag.lower() in tag.lower():  # 将比较操作转换为小写，避免大小写敏感问题\n",
    "            return target_tag\n",
    "    return tag\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_excel(\"data_field/repo_list_github_field.xlsx\")\n",
    "\n",
    "\n",
    "def process_tags(row):\n",
    "    all_tags = row[\"field\"].split(', ')\n",
    "    processed_tags = [replace_tags(tag.strip()) for tag in all_tags]\n",
    "    return ', '.join(processed_tags)\n",
    "\n",
    "\n",
    "df[\"field\"] = df.apply(process_tags, axis=1)\n",
    "\n",
    "\n",
    "all_tags = ', '.join(df[\"field\"]).split(', ')\n",
    "tag_counts = Counter(all_tags)\n",
    "tag_df = pd.DataFrame(tag_counts.items(), columns=[\"Tag\", \"Count\"])\n",
    "tag_df_sorted = tag_df.sort_values(by=\"Count\", ascending=False).reset_index(drop=True)\n",
    "print(tag_df_sorted)\n",
    "\n",
    "\n",
    "tags_with_repositories = []\n",
    "\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    tags = row[\"field\"].split(', ')\n",
    "    for tag in tags:\n",
    "        tags_with_repositories.append((tag, row[\"repo_name\"]))\n",
    "\n",
    "\n",
    "tags_repositories_df = pd.DataFrame(tags_with_repositories, columns=[\"Tag\", \"Repository\"])\n",
    "tags_repositories_sorted_df = tags_repositories_df.groupby(\"Tag\").agg(\n",
    "    {\"Repository\": lambda x: list(x)}).reset_index()\n",
    "print(tags_repositories_sorted_df)\n",
    "\n",
    "# 使用相对路径保存文件\n",
    "output_file_path = 'data_field/tags_repositories_statistics.xlsx'\n",
    "with pd.ExcelWriter(output_file_path) as writer:\n",
    "    tag_df_sorted.to_excel(writer, sheet_name=\"Tag Counts\", index=False)\n",
    "    tags_repositories_sorted_df.to_excel(writer, sheet_name=\"Tags with Repositories\", index=False)\n",
    "\n",
    "\n",
    "print(f\"Output saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后的文件已保存到: data_field/field_add_Q_2.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def merge_excel_files(file1, file2, output_file):\n",
    "    # 读取第一个 Excel 文件\n",
    "    df1 = pd.read_excel(file1)\n",
    "    # 读取第二个 Excel 文件\n",
    "    df2 = pd.read_excel(file2)\n",
    "    \n",
    "    # 通过 'id' 字段将两个 DataFrame 进行合并，使用左连接\n",
    "    merged_df = pd.merge(df1, df2[['id', '2022Q3', '2022Q4', '2023Q1', '2023Q2', '2023Q3', '2023Q4', '2024Q1', '2024Q2', '2024Q3']], on='id', how='left')\n",
    "    \n",
    "    # 将合并后的 DataFrame 保存到新的 Excel 文件中\n",
    "    merged_df.to_excel(output_file, index=False)\n",
    "    print(f\"合并后的文件已保存到: {output_file}\")\n",
    "\n",
    "# 调用\n",
    "file1 = 'data_field/repo_list_gitee_company.xlsx'\n",
    "file2 = 'data_field/repo_gitee_openrank_Q.xlsx'\n",
    "output_file = 'data_field/field_add_Q_2.xlsx'\n",
    "merge_excel_files(file1, file2, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           2022Q3  2022Q4  2023Q1  2023Q2  2023Q3  2023Q4  2024Q1  2024Q2  \\\n",
      "company                                                                     \n",
      "Alibaba      4.55    3.21    2.80    2.15    2.34    1.59    1.00    0.86   \n",
      "Huawei       3.64    3.13    2.59    2.76    2.44    2.15    2.02    1.96   \n",
      "openKylin   17.62   19.76   19.51   20.89   20.91   21.74   22.32   24.01   \n",
      "\n",
      "           2024Q3  \n",
      "company            \n",
      "Alibaba      0.50  \n",
      "Huawei       1.61  \n",
      "openKylin   22.75  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 读取 Excel 文件\n",
    "df = pd.read_excel('data_field/field_add_Q_2.xlsx')\n",
    "\n",
    "# 去除包含 0 的行\n",
    "df = df[(df!= 0).all(axis=1)]\n",
    "\n",
    "\n",
    "filtered_df = df[df['company'].isin(['Huawei', 'Alibaba', 'openKylin'])]\n",
    "\n",
    "columns_to_check =['2022Q3', '2022Q4', '2023Q1', '2023Q2', '2023Q3', '2023Q4', '2024Q1', '2024Q2', '2024Q3']\n",
    "\n",
    "\n",
    "grouped_df = filtered_df.groupby('company')\n",
    "\n",
    "grouped_mean = grouped_df[columns_to_check].mean().round(2)\n",
    "print(grouped_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2022Q3</th>\n",
       "      <th>2022Q4</th>\n",
       "      <th>2023Q1</th>\n",
       "      <th>2023Q2</th>\n",
       "      <th>2023Q3</th>\n",
       "      <th>2023Q4</th>\n",
       "      <th>2024Q1</th>\n",
       "      <th>2024Q2</th>\n",
       "      <th>2024Q3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alibaba</th>\n",
       "      <td>4.55</td>\n",
       "      <td>3.21</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1.59</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huawei</th>\n",
       "      <td>3.64</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.44</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openKylin</th>\n",
       "      <td>17.62</td>\n",
       "      <td>19.76</td>\n",
       "      <td>19.51</td>\n",
       "      <td>20.89</td>\n",
       "      <td>20.91</td>\n",
       "      <td>21.74</td>\n",
       "      <td>22.32</td>\n",
       "      <td>24.01</td>\n",
       "      <td>22.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           2022Q3  2022Q4  2023Q1  2023Q2  2023Q3  2023Q4  2024Q1  2024Q2  \\\n",
       "company                                                                     \n",
       "Alibaba      4.55    3.21    2.80    2.15    2.34    1.59    1.00    0.86   \n",
       "Huawei       3.64    3.13    2.59    2.76    2.44    2.15    2.02    1.96   \n",
       "openKylin   17.62   19.76   19.51   20.89   20.91   21.74   22.32   24.01   \n",
       "\n",
       "           2024Q3  \n",
       "company            \n",
       "Alibaba      0.50  \n",
       "Huawei       1.61  \n",
       "openKylin   22.75  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
